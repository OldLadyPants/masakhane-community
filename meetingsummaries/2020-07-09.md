# Masakhane Meeting Notes: 09/07/2020

- Time: 19:00
- Number of Attendees: 17 
- Notes taken by: Julia Kreutzer and Lerato Louis

# Introduction

- Julia - Introduces herself, as this week's meeting host and welcomes everybody. She runs through the following administrative points:
    - The general structure of weekly meetings (from the introduction of new members, to opening the floor for weekly initiative updates)
    - Julia mentions that meetings are recorded, for note taking purposes and that these recordings don't get published. She also speaks on the purpose of taking meeting notes, 
      which is to allow all (present and absent) to stay updated and informed on the community's current affairs. She then invites those who attended the
      WiNLP workshop (which is a part of the ACL conference 2020), to share their thoughts, insights and highlights.
      
#  Progress Update

- Chris - Steps forward to share what he learned during the workshop and conference and touches on the paper (he and Bona) he submitted and presented on low resource 
          languages (https://masakhane-nlp.slack.com/files/USJJ73P6V/F014KMUC466/web_emnlp_2020.pdf). 
          Outside of the interesting topics and ideas he got to see (zero-shot machine learning; multilingual transfer learning), the one thing that stood out to him is how
          open people are to acknowledging that there are problems with low resource languages and how dedicated they are to doing something about it. He notes that not 
          many know about Masakhane but that he used the discussions he engaged in, as opportunities to make Masakhane and the work we do, known. This, he says, received 
          positive feedback.
  - He met a number of people who upon hearing about Masakhane, were open to collaborating on projects that focus on trying to integrate low resource African languages. 
  - He wasn't able to spend much time at the ACL conference, as he had other commitments, but he was impressed with the paracrawl data and the DDS multilingual NMT papers
    he learned about at the conference.
  - He also met up with a gentleman named Kenneth, who has a paracrawl project which essentailly goes through the web, looking for parallel data between languages. This data
    is used to train MT models, through sentence by sentence alighnment. This project has mostly focussed on high resource European languages, but Kenneth is open to its use.
  - He also notes a paradigm shift towards multilingual translation frameworks, where researchers train models to interact between languages. These translations 
          are now leaning towards translating from African language to African language, as opposed to translating from African language to European language.
          
 - Julia - affirms Chris' positive experience, appreciating among a number of things, how he used discussion windows during the workshop (and conference) to alert members of the 
           broader NLP and MT community to the existence and function of Masakhane. She notes that we've since gotten a number of new members from ACLR. She encourages Masakhane 
           community members to reach out, to not only have internal collaborations but to have external collaborations too. This may lead to collaborations with people with 
           funding projects, certain expertise and experience. She asked Chris to compile a doc to collect the insights collected at the workshop and conference, to allow 
           Masakhanean's to catch up on the contents of both. 
    - She also draws our attention to an upcoming low resource MT workshop (https://sites.google.com/view/loresmt/), as another opportunity for collaboration and paper 
      submission.   
    - On the subject of Kenneth's paracrawl project, Julia mentions how one of the bottlenecks is being able to identify a language as necessity to being 
      able to crawl it. But Kenneth apparently has a Somali dataset that he's been able to crawl, and use in the paper he submitted for the ACL conference.
      (https://s3.amazonaws.com/web-language-models/paracrawl/bonus/en-so.tmx.gz).
          
# Data Updates          
          
- Vukosi - Greets everyone, then announces (as a general update) that for the AI4D challenge, there are now four teams that have since been identified to
           continue working on more data collection and adjustments. This means there might be more data available to the Masakhane project within the next few months.
  - With regards to data, he also mentions that he's on the steering committee for something called the Lakuna fund (http://www.statmt.org/wmt20/), which will be 
    launching next week. This fund is managing about $5 million U.S dollars, which will go towards data collection in areas that are underrepresented in machine learning. 
    For the first call, one part will focus on natural language processing, the other on agriculture. This will be an opportunity for Masakhanean's who are focussing on data 
    collection and setting up benchmarks, to apply for funding.
 
  - Julia - Commends the opportunity then asks Vukosi to further explain what kind of datasets they'd be interested in, in NLP.
 
  - Vukosi - Responds by saying, at the moment, the scope of the fund is pretty wide/ broad. It won't necessarily be focussed on specific language types, allowing for there to 
             be a focus on various downstream tasks. What will be important is the RFP that's about to come out which will give insight into the parameters of the fund, which 
             will help clarify who qualifies for funding.
 
  - Julia - Asks Vukosi how the data will be shared?
 
  - Vukosi - Mentions that the RFP of the licencing will have certain requirements, which will most probably be open licencing by default.
 
  - Julia - Contextualizes her question by mentioning the importance of openness and transparency, regarding data and models for Masakhane (as one of its principles). 
            She also mentions that transparency allows scaling, as it allows engagement from the widest group of people possible, in that area of research.
         - Related to this, someone from the WMT (a yearly competition for ML translators) has reached out to Masakhane, as they are planning to include African languages 
           in the competition for next year. This will challenge everyone to work with low resource languages in a frame they're used to.
 
- Christopher - Introduces himself, mentioning that he's from RIT and has been involved in a project that translates French texts into Bambara (a common language in Mali).
                They've spend about a year on the project, which has seen an acceleration over the past month or so, where obtaining parallel texts between French and Bambara 
                are concerned. In some cases, even obtaining parallel texts between French, Bambara and English. Some of their data sources are medical manuscripts. 
                They're in the process of creating an inventory of all the text they have. They are also in the process of cleaning data, to fix mistranslations and 
                text  misalignments. Some of the texts are aligned only at paragraph level and they're in the process of narrowing it down to sentence level alignment.
   
- Chris - Proposed that we compile a list of all of Masakhane's available datasets, storing and updating them from a centralized location. He argues that this will make 
          collaborations and data structuring easier. He also notes that it'll make it easier to know how much see data is available, with all the other Africa languages.
          He volunteers to help structure this.
   
  - Julia - Acknowledges the importance of this, tying it to the dataset hosting problem Masakhane still needs to address. Should our datasets be hosted externally, we'll  
          need to create a directory to point people to. We also want to make it as easy as possible for others to access and work our data. She suggests that we have this 
          on the website, as it'll be the first landing page for external researchers. Here's a list of datasets 
          (https://github.com/masakhane-io/masakhane-community/blob/master/list-of-datasets.md) where a collection has been started for some of the languages. It's inconclusive 
          at this stage but has links to different corpora. Julia suggests we enrich this list, possibly (and initially) through GitHub.
  -  Ignatius - Makes a comment on properly describing the data we currently have on GitHub. He mentions how the data, currently captured in a two column format, could be 
               stored in four columns, while we prepare to access it from Masakhane's website. He encourages those who have datasets on GitHub to create good 
               README markdown files, to help people to understand the structure of their datasets.
    - On the subject of aligning three languages, he also asks if there'd be a way to build a dataset for more than two languages. To which Julia says yes, and recommends 
      joining pairwise parallel datasets and seeing, at points that alight, if it'll be possible to add a third language to it.
    
  - Christopher - Steps forward and mentions how they luckily stumbled on a webpage that has a small triple translation dataset (https://dokotoro.org/) which was done by a 
                  former peace corp volunteer in Mali, who is fluent in French, Bambara and English. 
 
- Allahsera - Raises a name entity recognition related question. He (and his team) were tasked with finding a Bambara news website. They haven't been able to find one, so he
              wants to know whether there are alternative ways to get data so they can do name entity recognition.
               
   - Ignatius - In response to this, asks if they would have any other local news sources (such as local news papers) that they could crawl. 
 
   - Allahsera - Says they have local verbal sources, not text.
 
   - Ignatius - Points out that if the datasource is limited to the bible, the name densities will differ from the more contemporary use of the language. He then redirects
                Allahsera back to David.
   
   - Julia - Suggests checking the 666 Wikipedia pages of Bambara that exist. She isn't sure of how clean the data on Wikipedia is but suggests it may be worthwhile. The name
             entities contained therein, may not be as diverse or as up-to-date with the colloqial use of the language but there may topics in there that may be useful.

- Ahmed - Asks why most of the focus is on bible and domain specific data. He also asks if this can guarantee a good translation model. He adds further, whether it'd be better
          to try search for translations of books as opposed to using the news, bible or domain specific datasets. He also reflects on how using books would reflect real time 
          human conversations.

  - Julia - Responds by first highlighting the reason why Masakhane has been working with JW300 sources. That reason being, for many languages is the only resource. She mentions 
            how initially, Masakhane wanted to set up an easy way to run a machine translation benchmark for available data without having to crawl the data first.
            The overall goal is to move away from domain specific data. Julia also says in instances that involve building conversational translaion models, its good to look at 
            books. There have been digitization projects but notes that they're pretty bad at capturing low resource languages. But where available, books would be great as they
            provide greater cultural insights, than if you start from English.
  
  - Ahmed - Asks if mixing data sources is bad/ confuses the model. To which Julia points out how at this stage, resources are sparce, so mixing helps, because you get more 
            data (as well as data augmentation). Noisy data can help too, at times. 
  
# Initiatives/ Comments/ Questions 

- Bona - In response to Ignatius' question regarding building datasets for more than two languages, suggests having native language speakers translate as opposed to trying to
         build models that translate between three or more languages.

- Ignatius - Congratulates Chris and Bona on their graduation. He then goes on to mention that after the African NLP, he thought it might be a good idea to publish overviews
             on conference presentations, the methods and languages that featured the most, in an attempt to see how we improve over time. This may help Masakhane to get 
             more PR.

# Other Notes     

- Link to the website where Christopher (and the RIT team) found triple aligned Bambara-French-English data (https://gafe.dokotoro.org/multi.html).

Then Julia and Lerato stopped taking notes, but if anyone can help expand these, that would be useful.
          
